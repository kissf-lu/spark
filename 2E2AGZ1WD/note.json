{
  "paragraphs": [
    {
      "text": "%md \n\n### \u003ccenter\u003eSpark ML 机器学习LAB- 森林植被预测\u003c/center\u003e\n\n---",
      "user": "hadoop",
      "dateUpdated": "2019-01-01 16:50:38.573",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003e\u003ccenter\u003eSpark ML 机器学习LAB- 森林植被预测\u003c/center\u003e\u003c/h3\u003e\n\u003chr/\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1546069554646_826601515",
      "id": "20181229-154554_1028883481",
      "dateCreated": "2018-12-29 15:45:54.646",
      "dateStarted": "2019-01-01 16:50:38.574",
      "dateFinished": "2019-01-01 16:50:38.579",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": " 初始化环境",
      "text": "import scala.util.Random\n\nimport org.apache.spark.sql.functions._\nimport org.apache.spark.sql.DataFrame\n\nimport org.apache.spark.ml.{Pipeline, PipelineModel}\nimport org.apache.spark.ml.linalg.{Vector, Vectors}\nimport org.apache.spark.ml.feature.{VectorIndexer, VectorAssembler}\nimport org.apache.spark.ml.classification.{DecisionTreeClassifier, RandomForestClassifier, RandomForestClassificationModel}\n\nimport org.apache.spark.ml.tuning.{ParamGridBuilder, TrainValidationSplit}\nimport org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
      "user": "hadoop",
      "dateUpdated": "2019-01-01 18:00:12.429",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "tableHide": false,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "import scala.util.Random\nimport org.apache.spark.sql.functions._\nimport org.apache.spark.sql.DataFrame\nimport org.apache.spark.ml.{Pipeline, PipelineModel}\nimport org.apache.spark.ml.linalg.{Vector, Vectors}\nimport org.apache.spark.ml.feature.{VectorIndexer, VectorAssembler}\nimport org.apache.spark.ml.classification.{DecisionTreeClassifier, RandomForestClassifier, RandomForestClassificationModel}\nimport org.apache.spark.ml.tuning.{ParamGridBuilder, TrainValidationSplit}\nimport org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1546069915360_1745480198",
      "id": "20181229-155155_182595759",
      "dateCreated": "2018-12-29 15:51:55.360",
      "dateStarted": "2019-01-01 16:36:12.107",
      "dateFinished": "2019-01-01 16:36:13.624",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "HDFS 数据文件路径配置",
      "text": "// hdfs 路径\nval dir_base \u003d \"hdfs:///user/hadoop/spark/covtype\"\nval dataWithoutHeaded \u003d spark.read.\n  option(\"inferSchema\", true).\n  option(\"header\", false).\n  csv(s\"${dir_base}/covtype.data\")\n  \n  \n\n\n",
      "user": "hadoop",
      "dateUpdated": "2019-01-01 16:45:16.269",
      "config": {
        "colWidth": 6.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "title": true,
        "tableHide": true,
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "dir_base: String \u003d hdfs:///user/hadoop/spark/covtype\ndataWithoutHeaded: org.apache.spark.sql.DataFrame \u003d [_c0: int, _c1: int ... 53 more fields]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1546069998832_-1691260314",
      "id": "20181229-155318_361099773",
      "dateCreated": "2018-12-29 15:53:18.832",
      "dateStarted": "2019-01-01 16:36:15.794",
      "dateFinished": "2019-01-01 16:36:32.334",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "数据集的表头名制作",
      "text": "val colNames \u003d Seq(\n    \"Elevation\", \"Aspect\", \"Slope\",\n    \"Horizontal_Distance_To_Hydrology\", \"Vertical_Distance_To_Hydrology\",\n    \"Horizontal_Distance_To_Roadways\",\n    \"Hillshade_9am\", \"Hillshade_Noon\", \"Hillshade_3pm\", \"Horizontal_Distance_To_Fire_Points\"\n) ++ ((0 until 4).map(i \u003d\u003e s\"Wilderness_Area_$i\")\n) ++ ((0 until 40).map(i \u003d\u003e s\"Soil_Type_$i\")\n) ++ Seq(\"Cover_Type\")\nval data \u003d dataWithoutHeaded.\n  toDF(colNames:_*).\n  withColumn(\"Cover_Type\", $\"Cover_Type\".cast(\"double\"))\n  ",
      "user": "hadoop",
      "dateUpdated": "2019-01-01 18:00:29.431",
      "config": {
        "colWidth": 6.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "title": true,
        "tableHide": true,
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "colNames: Seq[String] \u003d List(Elevation, Aspect, Slope, Horizontal_Distance_To_Hydrology, Vertical_Distance_To_Hydrology, Horizontal_Distance_To_Roadways, Hillshade_9am, Hillshade_Noon, Hillshade_3pm, Horizontal_Distance_To_Fire_Points, Wilderness_Area_0, Wilderness_Area_1, Wilderness_Area_2, Wilderness_Area_3, Soil_Type_0, Soil_Type_1, Soil_Type_2, Soil_Type_3, Soil_Type_4, Soil_Type_5, Soil_Type_6, Soil_Type_7, Soil_Type_8, Soil_Type_9, Soil_Type_10, Soil_Type_11, Soil_Type_12, Soil_Type_13, Soil_Type_14, Soil_Type_15, Soil_Type_16, Soil_Type_17, Soil_Type_18, Soil_Type_19, Soil_Type_20, Soil_Type_21, Soil_Type_22, Soil_Type_23, Soil_Type_24, Soil_Type_25, Soil_Type_26, Soil_Type_27, Soil_Type_28, Soil_Type_29, Soil_Type_30, Soil_Type_31, Soil_Type_32, Soil_Type_33, Soil_Type_34, Soil_...data: org.apache.spark.sql.DataFrame \u003d [Elevation: int, Aspect: int ... 53 more fields]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1546329393882_-1611175771",
      "id": "20190101-155633_944444497",
      "dateCreated": "2019-01-01 15:56:33.883",
      "dateStarted": "2019-01-01 16:36:20.391",
      "dateFinished": "2019-01-01 16:36:34.220",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "函数定义",
      "text": "// --------------------------- 数据的转换函数 ------------------------\n\n/*\n数据的多列转换为非热键的单列数据类型：\na: Wilderness_Area 野地类型\nb: Soil_Type 土壤类型\n**/ \n\ndef unencodeOneHot(data: DataFrame): DataFrame \u003d {\n    // 二进制向量转换为 OneHot编码： 1.0的索引值为单点数据： (0, 0, 1, 0, 0) -\u003e 2.0\n    val unhotUDF \u003d udf((vec: Vector) \u003d\u003e vec.toArray.indexOf(1.0).toDouble)\n    // \n    val wildernessCols \u003d (0 until 4).map(i \u003d\u003e s\"Wilderness_Area_$i\").toArray\n    \n    // 获取野地类型\n    val wildernessAssembler \u003d new VectorAssembler().\n      setInputCols(wildernessCols).\n      setOutputCol(\"wilderness\")\n    // 获取二进制向量的， 丢弃wilderness的\n    val withWilderness \u003d wildernessAssembler.transform(data).\n      drop(wildernessCols:_*).\n      withColumn(\"wilderness\", unhotUDF($\"wilderness\"))\n    \n    // 转换二进制土壤类型指标为单值指标\n    val soilCols \u003d (0 until 40).map(i \u003d\u003e s\"Soil_Type_$i\").toArray\n    val soilAssembler \u003d new VectorAssembler().\n      setInputCols(soilCols).\n      setOutputCol(\"soil\")\n    soilAssembler.transform(withWilderness).\n      drop(soilCols:_*).\n      withColumn(\"soil\", unhotUDF($\"soil\"))  // 获取(0, ..., 1.0, 0, ..) -\u003e i i为1.0的索引值\n    \n}\n\n// -------------------------- 评估函数---------------------------------\n\n/*宽表转换为长表\nds: 需要转换的DF数据\n\ncol: 转换的列列表\n**/\ndef getTDataset(ds: DataFrame, col: Array[String]): DataFrame \u003d {\n    val dsSch \u003d ds.schema\n    ds.flatMap(r \u003d\u003e {\n      (0 until r.size).map(i \u003d\u003e {\n        (dsSch(i).name, r.getLong(i))\n      })\n    }).toDF(col:_*)\n}\n\n/*提取agg聚合函数的col名，将聚合的表头替换为原始的列表表头\n\n如： sum(col1) -\u003e col1, max(col2) -\u003e col2\n\n**/\ndef aggCol2Col(col: String) \u003d {\n    val reg \u003d raw\"(\\D+)\\((\\w+)\\)\".r\n    col match {\n        case reg(_, k, _*) \u003d\u003e k\n    }\n}\n\n\n/*获取预测数据的预测只与正确值同统计矩阵\n\nlabelRange： 测试标签的取值范围列表，用于pivot函数的lable输入参数\n**/\ndef getPredictionCount(data: DataFrame, label: String, labelRange: Array[Int]): DataFrame \u003d {\n    data.groupBy(label).\n      pivot(\"prediction\", labelRange).\n      count.na.fill(0.0).orderBy(label)\n}\n\n/*获取DF数值列的纵向和统计结果\nfunStr: 统计表表头的转换函数： 比如aggCol2Col函数，提取原始表名\n**/\ndef getAggRowDF(data: DataFrame, funStr: String\u003d\"sum\") \u003d {\n  // 数字特征的预测结果列\n  val colName \u003d data.columns.tail\n  // sum 聚合\n  val sumCols \u003d data.agg(colName.map(i \u003d\u003e s\"$i\" -\u003e funStr).toMap)\n  // 表头替换 添加sum行表头\n  sumCols.\n    toDF(sumCols.columns.map(aggCol2Col):_*)\n}\n\n\n\n\n",
      "user": "hadoop",
      "dateUpdated": "2019-01-01 17:59:04.953",
      "config": {
        "colWidth": 6.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "tableHide": false,
        "title": true,
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "unencodeOneHot: (data: org.apache.spark.sql.DataFrame)org.apache.spark.sql.DataFrame\ngetTDataset: (ds: org.apache.spark.sql.DataFrame, col: Array[String])org.apache.spark.sql.DataFrame\naggCol2Col: (col: String)String\ngetPredictionCount: (data: org.apache.spark.sql.DataFrame, label: String, labelRange: Array[Int])org.apache.spark.sql.DataFrame\ngetAggRowDF: (data: org.apache.spark.sql.DataFrame, funStr: String)org.apache.spark.sql.DataFrame\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1546328955339_1309445448",
      "id": "20190101-154915_2061646246",
      "dateCreated": "2019-01-01 15:49:15.339",
      "dateStarted": "2019-01-01 16:37:12.386",
      "dateFinished": "2019-01-01 16:37:15.955",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "数据集划分: 9 ： 1 划分训练数据与测试数据",
      "text": "// traindata and testdata split\n\nval Array(trainData, testData) \u003d data.randomSplit(Array(0.9, 0.1))\n\n// cache data\ntrainData.cache\ntestData.cache\n",
      "user": "hadoop",
      "dateUpdated": "2019-01-01 16:44:53.982",
      "config": {
        "colWidth": 6.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "title": true,
        "tableHide": false,
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "trainData: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] \u003d [Elevation: int, Aspect: int ... 53 more fields]\ntestData: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] \u003d [Elevation: int, Aspect: int ... 53 more fields]\nres18: trainData.type \u003d [Elevation: int, Aspect: int ... 53 more fields]\nres19: testData.type \u003d [Elevation: int, Aspect: int ... 53 more fields]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1546329007795_432650001",
      "id": "20190101-155007_993786457",
      "dateCreated": "2019-01-01 15:50:07.795",
      "dateStarted": "2019-01-01 16:37:23.207",
      "dateFinished": "2019-01-01 16:37:24.868",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "训练数据 和 测试数据的数据转换",
      "text": "// 编码转换\nval unencTrainData \u003d unencodeOneHot(trainData)\nval unencTestData \u003d unencodeOneHot(testData)\n",
      "user": "hadoop",
      "dateUpdated": "2019-01-01 16:44:53.995",
      "config": {
        "colWidth": 6.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "tableHide": false,
        "title": true,
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "unencTrainData: org.apache.spark.sql.DataFrame \u003d [Elevation: int, Aspect: int ... 11 more fields]\nunencTestData: org.apache.spark.sql.DataFrame \u003d [Elevation: int, Aspect: int ... 11 more fields]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1546069964673_688027722",
      "id": "20181229-155244_1250204333",
      "dateCreated": "2018-12-29 15:52:44.673",
      "dateStarted": "2019-01-01 16:37:27.141",
      "dateFinished": "2019-01-01 16:37:28.001",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "pipeline 管道转换配置",
      "text": "// 特征向量转换器\nval assembler \u003d new VectorAssembler().\n  setInputCols(unencTrainData.columns.filter(_ !\u003d \"Cover_Type\")).\n  setOutputCol(\"featureVector\")\n// 特质分类转换器\nval indexer \u003d new VectorIndexer().\n  setMaxCategories(40).\n  setInputCol(\"featureVector\").\n  setOutputCol(\"indexedVector\")\n// 随机数分类器\nval classifier \u003d new RandomForestClassifier().\n  setSeed(Random.nextLong).\n  setLabelCol(\"Cover_Type\").\n  setFeaturesCol(\"indexedVector\").\n  setPredictionCol(\"prediction\").\n  setImpurity(\"entropy\").\n  setMaxDepth(20).\n  setMaxBins(220)\n\n\nval pipeline \u003d new Pipeline().setStages(Array(assembler, indexer, classifier))\n",
      "user": "hadoop",
      "dateUpdated": "2019-01-01 16:44:54.015",
      "config": {
        "colWidth": 6.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "title": true,
        "tableHide": false,
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "assembler: org.apache.spark.ml.feature.VectorAssembler \u003d vecAssembler_9b79ec3ff6d6\nindexer: org.apache.spark.ml.feature.VectorIndexer \u003d vecIdx_15004e6696ff\nclassifier: org.apache.spark.ml.classification.RandomForestClassifier \u003d rfc_3c29a232288d\npipeline: org.apache.spark.ml.Pipeline \u003d pipeline_4c2647dcdc55\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1546311839060_2001570288",
      "id": "20190101-110359_531644912",
      "dateCreated": "2019-01-01 11:03:59.060",
      "dateStarted": "2019-01-01 16:37:30.571",
      "dateFinished": "2019-01-01 16:37:31.816",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "训练数据的多参数拟合",
      "text": "val paramGrid \u003d new ParamGridBuilder().\n  addGrid(classifier.minInfoGain, Seq(0.0, 0.05)).\n  addGrid(classifier.numTrees, Seq(1, 10)).\n  build()\n\nval multiclassEval \u003d new MulticlassClassificationEvaluator().\n  setLabelCol(\"Cover_Type\").\n  setPredictionCol(\"prediction\").\n  setMetricName(\"accuracy\")\n\nval validator \u003d new TrainValidationSplit().\n  setSeed(Random.nextLong).\n  setEstimator(pipeline).\n  setEvaluator(multiclassEval).\n  setEstimatorParamMaps(paramGrid).\n  setTrainRatio(0.9)\n\nval validatorModel \u003d validator.fit(unencTrainData)\n\n",
      "user": "hadoop",
      "dateUpdated": "2019-01-01 17:59:17.522",
      "config": {
        "colWidth": 6.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "title": true,
        "tableHide": true,
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "paramGrid: Array[org.apache.spark.ml.param.ParamMap] \u003d\nArray({\n\trfc_3c29a232288d-minInfoGain: 0.0,\n\trfc_3c29a232288d-numTrees: 1\n}, {\n\trfc_3c29a232288d-minInfoGain: 0.0,\n\trfc_3c29a232288d-numTrees: 10\n}, {\n\trfc_3c29a232288d-minInfoGain: 0.05,\n\trfc_3c29a232288d-numTrees: 1\n}, {\n\trfc_3c29a232288d-minInfoGain: 0.05,\n\trfc_3c29a232288d-numTrees: 10\n})\nmulticlassEval: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator \u003d mcEval_665f410c50e8\nvalidator: org.apache.spark.ml.tuning.TrainValidationSplit \u003d tvs_2bbd2298a9a4\nvalidatorModel: org.apache.spark.ml.tuning.TrainValidationSplitModel \u003d tvs_2bbd2298a9a4\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1546329991805_180208075",
      "id": "20190101-160631_1443147183",
      "dateCreated": "2019-01-01 16:06:31.806",
      "dateStarted": "2019-01-01 16:37:52.902",
      "dateFinished": "2019-01-01 16:44:18.263",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "从多组训练模型中获取最佳训练模型",
      "text": "val bestModel \u003d validatorModel.bestModel\n// \nval forestModel \u003d bestModel.asInstanceOf[PipelineModel].stages.last.asInstanceOf[RandomForestClassificationModel]\n// 模型参数\nforestModel.featureImportances.toArray.\n  zip(unencTrainData.columns.filter(_ !\u003d \"Cover_Type\")).\n  sorted.reverse.foreach(println)\n  ",
      "user": "hadoop",
      "dateUpdated": "2019-01-01 17:59:28.610",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "title": true,
        "tableHide": true,
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "bestModel: org.apache.spark.ml.Model[_] \u003d pipeline_4c2647dcdc55\nforestModel: org.apache.spark.ml.classification.RandomForestClassificationModel \u003d RandomForestClassificationModel (uid\u003drfc_3c29a232288d) with 10 trees\n(0.3757281097184595,Elevation)\n(0.15125858987528257,soil)\n(0.1064071892628181,Horizontal_Distance_To_Roadways)\n(0.10424001283509823,Horizontal_Distance_To_Fire_Points)\n(0.04762502216936916,Horizontal_Distance_To_Hydrology)\n(0.04243346140758059,Vertical_Distance_To_Hydrology)\n(0.038397936980035546,wilderness)\n(0.030548354266355698,Aspect)\n(0.03041389579453472,Hillshade_Noon)\n(0.028379455284066164,Hillshade_9am)\n(0.024805451911074496,Hillshade_3pm)\n(0.019762520495325103,Slope)\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1546330133340_-1935943304",
      "id": "20190101-160853_1978815652",
      "dateCreated": "2019-01-01 16:08:53.340",
      "dateStarted": "2019-01-01 16:47:17.679",
      "dateFinished": "2019-01-01 16:47:18.846",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n##  \u003ccenter\u003e模型的测试集合验证 与 模型评估\u003c/center\u003e\n---",
      "user": "hadoop",
      "dateUpdated": "2019-01-01 16:51:44.534",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003e\u003ccenter\u003e模型的测试集合验证 与 模型评估\u003c/center\u003e\u003c/h2\u003e\n\u003chr/\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1546332477867_1724485397",
      "id": "20190101-164757_1725714885",
      "dateCreated": "2019-01-01 16:47:57.867",
      "dateStarted": "2019-01-01 16:51:44.534",
      "dateFinished": "2019-01-01 16:51:44.543",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "测试集验证模型",
      "text": "val bstPrediction \u003d bestModel.transform(unencTestData)\n",
      "user": "hadoop",
      "dateUpdated": "2019-01-01 16:57:41.137",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "bstPrediction: org.apache.spark.sql.DataFrame \u003d [Elevation: int, Aspect: int ... 16 more fields]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1546332437655_-1803780736",
      "id": "20190101-164717_1695296736",
      "dateCreated": "2019-01-01 16:47:17.655",
      "dateStarted": "2019-01-01 16:52:15.976",
      "dateFinished": "2019-01-01 16:52:16.392",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "获取测试数据集的测试结果统计",
      "text": "// 统计矩阵： 对角线为正确预测数， 非对角线为错误\nval contDF \u003d getPredictionCount(data\u003dbstPrediction, label\u003d\"Cover_Type\", labelRange\u003d(1 to 7).toArray)\n// 获取矩阵的对角线值，将结果列cross_val左联接至原始表\n\n\n// 获取对角线的数值\n// 获取统计表的正确统计值DF\nval crossValDF \u003d contDF.map(r \u003d\u003e {\n    val idx \u003d r.getDouble(0).toInt\n    (idx, r.getLong(idx))\n}).toDF(\"Type\", \"cross_val\")\n\n// -----------------------------获取矩阵的对角线值，将结果列cross_val左联接至原始表---------\nval validateModelDF \u003d contDF.\n  join(crossValDF, contDF.col(\"Cover_Type\").equalTo(crossValDF.col(\"Type\")), \"left\").\n  drop(\"Type\")\n  \n\n// ----------------------------增加纵向求和行数据------------------------------------------\nval sumTypeDF \u003d getAggRowDF(data\u003dvalidateModelDF)\n// \nval sumRowTypeDF \u003d sumTypeDF.withColumn(\"Cover_Type\", lit(\"sum_val\"))\n// // // 根据columns 名称 做 表格的行数据增加\nval sumAllTypeOfCovert \u003d validateModelDF.unionByName(sumRowTypeDF)\n\n// ---------------------------缓存中间表---------------------\n\nsumAllTypeOfCovert.cache\n\n\n// ----------------------------统计表生成---------------------\n// val contData \u003d sumAllTypeOfCovert.show\n\nval staticPercentData \u003d sumAllTypeOfCovert.\n  withColumn(\"sum\", $\"1\" + $\"2\" + $\"3\" + $\"4\" + $\"5\" + $\"6\" + $\"7\").\n  withColumn(\"rat\", $\"cross_val\" / $\"sum_val\")\n  \n// ------------------------ sql 注册 -------------------------\n\nstaticPercentData.registerTempTable(\"staticPercentTable\")\n\n\n\n\n",
      "user": "hadoop",
      "dateUpdated": "2019-01-01 17:34:21.176",
      "config": {
        "colWidth": 6.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "title": true,
        "tableHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "contDF: org.apache.spark.sql.DataFrame \u003d [Cover_Type: double, 1: bigint ... 6 more fields]\ncrossValDF: org.apache.spark.sql.DataFrame \u003d [Type: int, cross_val: bigint]\nvalidateModelDF: org.apache.spark.sql.DataFrame \u003d [Cover_Type: double, 1: bigint ... 7 more fields]\nsumTypeDF: org.apache.spark.sql.DataFrame \u003d [4: bigint, 5: bigint ... 6 more fields]\nsumRowTypeDF: org.apache.spark.sql.DataFrame \u003d [4: bigint, 5: bigint ... 7 more fields]\nsumAllTypeOfCovert: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] \u003d [Cover_Type: string, 1: bigint ... 7 more fields]\nres131: sumAllTypeOfCovert.type \u003d [Cover_Type: string, 1: bigint ... 7 more fields]\norg.apache.spark.sql.AnalysisException: cannot resolve \u0027`sum_val`\u0027 given input columns: [sum, 5, 6, 2, 7, Cover_Type, 3, 1, cross_val, 4];;\n\u0027Project [Cover_Type#17875, 1#17750L, 2#17751L, 3#17752L, 4#17753L, 5#17754L, 6#17755L, 7#17756L, cross_val#17774L, sum#20414L, (cross_val#17774L / \u0027sum_val) AS rat#20425]\n+- AnalysisBarrier\n      +- Project [Cover_Type#17875, 1#17750L, 2#17751L, 3#17752L, 4#17753L, 5#17754L, 6#17755L, 7#17756L, cross_val#17774L, ((((((1#17750L + 2#17751L) + 3#17752L) + 4#17753L) + 5#17754L) + 6#17755L) + 7#17756L) AS sum#20414L]\n         +- Union\n            :- Project [cast(Cover_Type#17749 as string) AS Cover_Type#17875, 1#17750L, 2#17751L, 3#17752L, 4#17753L, 5#17754L, 6#17755L, 7#17756L, cross_val#17774L]\n            :  +- Project [Cover_Type#17749, 1#17750L, 2#17751L, 3#17752L, 4#17753L, 5#17754L, 6#17755L, 7#17756L, cross_val#17774L]\n            :     +- Join LeftOuter, (Cover_Type#17749 \u003d cast(Type#17773 as double))\n            :        :- Sort [Cover_Type#17749 ASC NULLS FIRST], true\n            :        :  +- Project [coalesce(nanvl(Cover_Type#230, cast(null as double)), cast(0.0 as double)) AS Cover_Type#17749, coalesce(1#17726L, cast(0.0 as bigint)) AS 1#17750L, coalesce(2#17727L, cast(0.0 as bigint)) AS 2#17751L, coalesce(3#17728L, cast(0.0 as bigint)) AS 3#17752L, coalesce(4#17729L, cast(0.0 as bigint)) AS 4#17753L, coalesce(5#17730L, cast(0.0 as bigint)) AS 5#17754L, coalesce(6#17731L, cast(0.0 as bigint)) AS 6#17755L, coalesce(7#17732L, cast(0.0 as bigint)) AS 7#17756L]\n            :        :     +- Project [Cover_Type#230, __pivot_count(1) AS `count` AS `count(1) AS ``count```#17725[0] AS 1#17726L, __pivot_count(1) AS `count` AS `count(1) AS ``count```#17725[1] AS 2#17727L, __pivot_count(1) AS `count` AS `count(1) AS ``count```#17725[2] AS 3#17728L, __pivot_count(1) AS `count` AS `count(1) AS ``count```#17725[3] AS 4#17729L, __pivot_count(1) AS `count` AS `count(1) AS ``count```#17725[4] AS 5#17730L, __pivot_count(1) AS `count` AS `count(1) AS ``count```#17725[5] AS 6#17731L, __pivot_count(1) AS `count` AS `count(1) AS ``count```#17725[6] AS 7#17732L]\n            :        :        +- Aggregate [Cover_Type#230], [Cover_Type#230, pivotfirst(prediction#5860, count(1) AS `count`#17709L, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 0, 0) AS __pivot_count(1) AS `count` AS `count(1) AS ``count```#17725]\n            :        :           +- Aggregate [Cover_Type#230, prediction#5860], [Cover_Type#230, prediction#5860, count(1) AS count(1) AS `count`#17709L]\n            :        :              +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Cover_Type#230, wilderness#1346, soil#1506, featureVector#5793, indexedVector#5809, rawPrediction#5825, probability#5842, UDF(rawPrediction#5825) AS prediction#5860]\n            :        :                 +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Cover_Type#230, wilderness#1346, soil#1506, featureVector#5793, indexedVector#5809, rawPrediction#5825, UDF(rawPrediction#5825) AS probability#5842]\n            :        :                    +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Cover_Type#230, wilderness#1346, soil#1506, featureVector#5793, indexedVector#5809, UDF(indexedVector#5809) AS rawPrediction#5825]\n            :        :                       +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Cover_Type#230, wilderness#1346, soil#1506, featureVector#5793, UDF(featureVector#5793) AS indexedVector#5809]\n            :        :                          +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Cover_Type#230, wilderness#1346, soil#1506, UDF(named_struct(Elevation_double_vecAssembler_9b79ec3ff6d6, cast(Elevation#120 as double), Aspect_double_vecAssembler_9b79ec3ff6d6, cast(Aspect#121 as double), Slope_double_vecAssembler_9b79ec3ff6d6, cast(Slope#122 as double), Horizontal_Distance_To_Hydrology_double_vecAssembler_9b79ec3ff6d6, cast(Horizontal_Distance_To_Hydrology#123 as double), Vertical_Distance_To_Hydrology_double_vecAssembler_9b79ec3ff6d6, cast(Vertical_Distance_To_Hydrology#124 as double), Horizontal_Distance_To_Roadways_double_vecAssembler_9b79ec3ff6d6, cast(Horizontal_Distance_To_Roadways#125 as double), Hillshade_9am_double_vecAssembler_9b79ec3ff6d6, cast(Hillshade_9am#126 as double), Hillshade_Noon_double_vecAssembler_9b79ec3ff6d6, cast(Hillshade_Noon#127 as double), Hillshade_3pm_double_vecAssembler_9b79ec3ff6d6, cast(Hillshade_3pm#128 as double), Horizontal_Distance_To_Fire_Points_double_vecAssembler_9b79ec3ff6d6, cast(Horizontal_Distance_To_Fire_Points#129 as double), wilderness, wilderness#1346, soil, soil#1506)) AS featureVector#5793]\n            :        :                             +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Cover_Type#230, wilderness#1346, UDF(soil#1439) AS soil#1506]\n            :        :                                +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Cover_Type#230, wilderness#1346, soil#1439]\n            :        :                                   +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Soil_Type_0#134, Soil_Type_1#135, Soil_Type_2#136, Soil_Type_3#137, Soil_Type_4#138, Soil_Type_5#139, Soil_Type_6#140, Soil_Type_7#141, Soil_Type_8#142, Soil_Type_9#143, Soil_Type_10#144, Soil_Type_11#145, Soil_Type_12#146, Soil_Type_13#147, ... 29 more fields]\n            :        :                                      +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Soil_Type_0#134, Soil_Type_1#135, Soil_Type_2#136, Soil_Type_3#137, Soil_Type_4#138, Soil_Type_5#139, Soil_Type_6#140, Soil_Type_7#141, Soil_Type_8#142, Soil_Type_9#143, Soil_Type_10#144, Soil_Type_11#145, Soil_Type_12#146, Soil_Type_13#147, ... 28 more fields]\n            :        :                                         +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Soil_Type_0#134, Soil_Type_1#135, Soil_Type_2#136, Soil_Type_3#137, Soil_Type_4#138, Soil_Type_5#139, Soil_Type_6#140, Soil_Type_7#141, Soil_Type_8#142, Soil_Type_9#143, Soil_Type_10#144, Soil_Type_11#145, Soil_Type_12#146, Soil_Type_13#147, ... 28 more fields]\n            :        :                                            +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Wilderness_Area_0#130, Wilderness_Area_1#131, Wilderness_Area_2#132, Wilderness_Area_3#133, Soil_Type_0#134, Soil_Type_1#135, Soil_Type_2#136, Soil_Type_3#137, Soil_Type_4#138, Soil_Type_5#139, Soil_Type_6#140, Soil_Type_7#141, Soil_Type_8#142, Soil_Type_9#143, ... 32 more fields]\n            :        :                                               +- Sample 0.9, 1.0, false, 4912836352977398653\n            :        :                                                  +- Sort [Elevation#120 ASC NULLS FIRST, Aspect#121 ASC NULLS FIRST, Slope#122 ASC NULLS FIRST, Horizontal_Distance_To_Hydrology#123 ASC NULLS FIRST, Vertical_Distance_To_Hydrology#124 ASC NULLS FIRST, Horizontal_Distance_To_Roadways#125 ASC NULLS FIRST, Hillshade_9am#126 ASC NULLS FIRST, Hillshade_Noon#127 ASC NULLS FIRST, Hillshade_3pm#128 ASC NULLS FIRST, Horizontal_Distance_To_Fire_Points#129 ASC NULLS FIRST, Wilderness_Area_0#130 ASC NULLS FIRST, Wilderness_Area_1#131 ASC NULLS FIRST, Wilderness_Area_2#132 ASC NULLS FIRST, Wilderness_Area_3#133 ASC NULLS FIRST, Soil_Type_0#134 ASC NULLS FIRST, Soil_Type_1#135 ASC NULLS FIRST, Soil_Type_2#136 ASC NULLS FIRST, Soil_Type_3#137 ASC NULLS FIRST, Soil_Type_4#138 ASC NULLS FIRST, Soil_Type_5#139 ASC NULLS FIRST, Soil_Type_6#140 ASC NULLS FIRST, Soil_Type_7#141 ASC NULLS FIRST, Soil_Type_8#142 ASC NULLS FIRST, Soil_Type_9#143 ASC NULLS FIRST, ... 31 more fields], false\n            :        :                                                     +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Wilderness_Area_0#130, Wilderness_Area_1#131, Wilderness_Area_2#132, Wilderness_Area_3#133, Soil_Type_0#134, Soil_Type_1#135, Soil_Type_2#136, Soil_Type_3#137, Soil_Type_4#138, Soil_Type_5#139, Soil_Type_6#140, Soil_Type_7#141, Soil_Type_8#142, Soil_Type_9#143, ... 31 more fields]\n            :        :                                                        +- Project [_c0#10 AS Elevation#120, _c1#11 AS Aspect#121, _c2#12 AS Slope#122, _c3#13 AS Horizontal_Distance_To_Hydrology#123, _c4#14 AS Vertical_Distance_To_Hydrology#124, _c5#15 AS Horizontal_Distance_To_Roadways#125, _c6#16 AS Hillshade_9am#126, _c7#17 AS Hillshade_Noon#127, _c8#18 AS Hillshade_3pm#128, _c9#19 AS Horizontal_Distance_To_Fire_Points#129, _c10#20 AS Wilderness_Area_0#130, _c11#21 AS Wilderness_Area_1#131, _c12#22 AS Wilderness_Area_2#132, _c13#23 AS Wilderness_Area_3#133, _c14#24 AS Soil_Type_0#134, _c15#25 AS Soil_Type_1#135, _c16#26 AS Soil_Type_2#136, _c17#27 AS Soil_Type_3#137, _c18#28 AS Soil_Type_4#138, _c19#29 AS Soil_Type_5#139, _c20#30 AS Soil_Type_6#140, _c21#31 AS Soil_Type_7#141, _c22#32 AS Soil_Type_8#142, _c23#33 AS Soil_Type_9#143, ... 31 more fields]\n            :        :                                                           +- Relation[_c0#10,_c1#11,_c2#12,_c3#13,_c4#14,_c5#15,_c6#16,_c7#17,_c8#18,_c9#19,_c10#20,_c11#21,_c12#22,_c13#23,_c14#24,_c15#25,_c16#26,_c17#27,_c18#28,_c19#29,_c20#30,_c21#31,_c22#32,_c23#33,... 31 more fields] csv\n            :        +- Project [_1#17770 AS Type#17773, _2#17771L AS cross_val#17774L]\n            :           +- SerializeFromObject [assertnotnull(assertnotnull(input[0, scala.Tuple2, true]))._1 AS _1#17770, assertnotnull(assertnotnull(input[0, scala.Tuple2, true]))._2 AS _2#17771L]\n            :              +- MapElements \u003cfunction1\u003e, interface org.apache.spark.sql.Row, [StructField(Cover_Type,DoubleType,false), StructField(1,LongType,true), StructField(2,LongType,true), StructField(3,LongType,true), StructField(4,LongType,true), StructField(5,LongType,true), StructField(6,LongType,true), StructField(7,LongType,true)], obj#17769: scala.Tuple2\n            :                 +- DeserializeToObject createexternalrow(Cover_Type#17749, 1#17750L, 2#17751L, 3#17752L, 4#17753L, 5#17754L, 6#17755L, 7#17756L, StructField(Cover_Type,DoubleType,false), StructField(1,LongType,true), StructField(2,LongType,true), StructField(3,LongType,true), StructField(4,LongType,true), StructField(5,LongType,true), StructField(6,LongType,true), StructField(7,LongType,true)), obj#17768: org.apache.spark.sql.Row\n            :                    +- Sort [Cover_Type#17749 ASC NULLS FIRST], true\n            :                       +- Project [coalesce(nanvl(Cover_Type#230, cast(null as double)), cast(0.0 as double)) AS Cover_Type#17749, coalesce(1#17726L, cast(0.0 as bigint)) AS 1#17750L, coalesce(2#17727L, cast(0.0 as bigint)) AS 2#17751L, coalesce(3#17728L, cast(0.0 as bigint)) AS 3#17752L, coalesce(4#17729L, cast(0.0 as bigint)) AS 4#17753L, coalesce(5#17730L, cast(0.0 as bigint)) AS 5#17754L, coalesce(6#17731L, cast(0.0 as bigint)) AS 6#17755L, coalesce(7#17732L, cast(0.0 as bigint)) AS 7#17756L]\n            :                          +- Project [Cover_Type#230, __pivot_count(1) AS `count` AS `count(1) AS ``count```#17725[0] AS 1#17726L, __pivot_count(1) AS `count` AS `count(1) AS ``count```#17725[1] AS 2#17727L, __pivot_count(1) AS `count` AS `count(1) AS ``count```#17725[2] AS 3#17728L, __pivot_count(1) AS `count` AS `count(1) AS ``count```#17725[3] AS 4#17729L, __pivot_count(1) AS `count` AS `count(1) AS ``count```#17725[4] AS 5#17730L, __pivot_count(1) AS `count` AS `count(1) AS ``count```#17725[5] AS 6#17731L, __pivot_count(1) AS `count` AS `count(1) AS ``count```#17725[6] AS 7#17732L]\n            :                             +- Aggregate [Cover_Type#230], [Cover_Type#230, pivotfirst(prediction#5860, count(1) AS `count`#17709L, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 0, 0) AS __pivot_count(1) AS `count` AS `count(1) AS ``count```#17725]\n            :                                +- Aggregate [Cover_Type#230, prediction#5860], [Cover_Type#230, prediction#5860, count(1) AS count(1) AS `count`#17709L]\n            :                                   +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Cover_Type#230, wilderness#1346, soil#1506, featureVector#5793, indexedVector#5809, rawPrediction#5825, probability#5842, UDF(rawPrediction#5825) AS prediction#5860]\n            :                                      +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Cover_Type#230, wilderness#1346, soil#1506, featureVector#5793, indexedVector#5809, rawPrediction#5825, UDF(rawPrediction#5825) AS probability#5842]\n            :                                         +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Cover_Type#230, wilderness#1346, soil#1506, featureVector#5793, indexedVector#5809, UDF(indexedVector#5809) AS rawPrediction#5825]\n            :                                            +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Cover_Type#230, wilderness#1346, soil#1506, featureVector#5793, UDF(featureVector#5793) AS indexedVector#5809]\n            :                                               +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Cover_Type#230, wilderness#1346, soil#1506, UDF(named_struct(Elevation_double_vecAssembler_9b79ec3ff6d6, cast(Elevation#120 as double), Aspect_double_vecAssembler_9b79ec3ff6d6, cast(Aspect#121 as double), Slope_double_vecAssembler_9b79ec3ff6d6, cast(Slope#122 as double), Horizontal_Distance_To_Hydrology_double_vecAssembler_9b79ec3ff6d6, cast(Horizontal_Distance_To_Hydrology#123 as double), Vertical_Distance_To_Hydrology_double_vecAssembler_9b79ec3ff6d6, cast(Vertical_Distance_To_Hydrology#124 as double), Horizontal_Distance_To_Roadways_double_vecAssembler_9b79ec3ff6d6, cast(Horizontal_Distance_To_Roadways#125 as double), Hillshade_9am_double_vecAssembler_9b79ec3ff6d6, cast(Hillshade_9am#126 as double), Hillshade_Noon_double_vecAssembler_9b79ec3ff6d6, cast(Hillshade_Noon#127 as double), Hillshade_3pm_double_vecAssembler_9b79ec3ff6d6, cast(Hillshade_3pm#128 as double), Horizontal_Distance_To_Fire_Points_double_vecAssembler_9b79ec3ff6d6, cast(Horizontal_Distance_To_Fire_Points#129 as double), wilderness, wilderness#1346, soil, soil#1506)) AS featureVector#5793]\n            :                                                  +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Cover_Type#230, wilderness#1346, UDF(soil#1439) AS soil#1506]\n            :                                                     +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Cover_Type#230, wilderness#1346, soil#1439]\n            :                                                        +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Soil_Type_0#134, Soil_Type_1#135, Soil_Type_2#136, Soil_Type_3#137, Soil_Type_4#138, Soil_Type_5#139, Soil_Type_6#140, Soil_Type_7#141, Soil_Type_8#142, Soil_Type_9#143, Soil_Type_10#144, Soil_Type_11#145, Soil_Type_12#146, Soil_Type_13#147, ... 29 more fields]\n            :                                                           +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Soil_Type_0#134, Soil_Type_1#135, Soil_Type_2#136, Soil_Type_3#137, Soil_Type_4#138, Soil_Type_5#139, Soil_Type_6#140, Soil_Type_7#141, Soil_Type_8#142, Soil_Type_9#143, Soil_Type_10#144, Soil_Type_11#145, Soil_Type_12#146, Soil_Type_13#147, ... 28 more fields]\n            :                                                              +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Soil_Type_0#134, Soil_Type_1#135, Soil_Type_2#136, Soil_Type_3#137, Soil_Type_4#138, Soil_Type_5#139, Soil_Type_6#140, Soil_Type_7#141, Soil_Type_8#142, Soil_Type_9#143, Soil_Type_10#144, Soil_Type_11#145, Soil_Type_12#146, Soil_Type_13#147, ... 28 more fields]\n            :                                                                 +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Wilderness_Area_0#130, Wilderness_Area_1#131, Wilderness_Area_2#132, Wilderness_Area_3#133, Soil_Type_0#134, Soil_Type_1#135, Soil_Type_2#136, Soil_Type_3#137, Soil_Type_4#138, Soil_Type_5#139, Soil_Type_6#140, Soil_Type_7#141, Soil_Type_8#142, Soil_Type_9#143, ... 32 more fields]\n            :                                                                    +- Sample 0.9, 1.0, false, 4912836352977398653\n            :                                                                       +- Sort [Elevation#120 ASC NULLS FIRST, Aspect#121 ASC NULLS FIRST, Slope#122 ASC NULLS FIRST, Horizontal_Distance_To_Hydrology#123 ASC NULLS FIRST, Vertical_Distance_To_Hydrology#124 ASC NULLS FIRST, Horizontal_Distance_To_Roadways#125 ASC NULLS FIRST, Hillshade_9am#126 ASC NULLS FIRST, Hillshade_Noon#127 ASC NULLS FIRST, Hillshade_3pm#128 ASC NULLS FIRST, Horizontal_Distance_To_Fire_Points#129 ASC NULLS FIRST, Wilderness_Area_0#130 ASC NULLS FIRST, Wilderness_Area_1#131 ASC NULLS FIRST, Wilderness_Area_2#132 ASC NULLS FIRST, Wilderness_Area_3#133 ASC NULLS FIRST, Soil_Type_0#134 ASC NULLS FIRST, Soil_Type_1#135 ASC NULLS FIRST, Soil_Type_2#136 ASC NULLS FIRST, Soil_Type_3#137 ASC NULLS FIRST, Soil_Type_4#138 ASC NULLS FIRST, Soil_Type_5#139 ASC NULLS FIRST, Soil_Type_6#140 ASC NULLS FIRST, Soil_Type_7#141 ASC NULLS FIRST, Soil_Type_8#142 ASC NULLS FIRST, Soil_Type_9#143 ASC NULLS FIRST, ... 31 more fields], false\n            :                                                                          +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Wilderness_Area_0#130, Wilderness_Area_1#131, Wilderness_Area_2#132, Wilderness_Area_3#133, Soil_Type_0#134, Soil_Type_1#135, Soil_Type_2#136, Soil_Type_3#137, Soil_Type_4#138, Soil_Type_5#139, Soil_Type_6#140, Soil_Type_7#141, Soil_Type_8#142, Soil_Type_9#143, ... 31 more fields]\n            :                                                                             +- Project [_c0#10 AS Elevation#120, _c1#11 AS Aspect#121, _c2#12 AS Slope#122, _c3#13 AS Horizontal_Distance_To_Hydrology#123, _c4#14 AS Vertical_Distance_To_Hydrology#124, _c5#15 AS Horizontal_Distance_To_Roadways#125, _c6#16 AS Hillshade_9am#126, _c7#17 AS Hillshade_Noon#127, _c8#18 AS Hillshade_3pm#128, _c9#19 AS Horizontal_Distance_To_Fire_Points#129, _c10#20 AS Wilderness_Area_0#130, _c11#21 AS Wilderness_Area_1#131, _c12#22 AS Wilderness_Area_2#132, _c13#23 AS Wilderness_Area_3#133, _c14#24 AS Soil_Type_0#134, _c15#25 AS Soil_Type_1#135, _c16#26 AS Soil_Type_2#136, _c17#27 AS Soil_Type_3#137, _c18#28 AS Soil_Type_4#138, _c19#29 AS Soil_Type_5#139, _c20#30 AS Soil_Type_6#140, _c21#31 AS Soil_Type_7#141, _c22#32 AS Soil_Type_8#142, _c23#33 AS Soil_Type_9#143, ... 31 more fields]\n            :                                                                                +- Relation[_c0#10,_c1#11,_c2#12,_c3#13,_c4#14,_c5#15,_c6#16,_c7#17,_c8#18,_c9#19,_c10#20,_c11#21,_c12#22,_c13#23,_c14#24,_c15#25,_c16#26,_c17#27,_c18#28,_c19#29,_c20#30,_c21#31,_c22#32,_c23#33,... 31 more fields] csv\n            +- Project [Cover_Type#17865, 1#17852L, 2#17854L, 3#17856L, 4#17849L, 5#17850L, 6#17851L, 7#17855L, cross_val#17853L]\n               +- Project [Cover_Type#17865, 1#17852L, 2#17854L, 3#17856L, 4#17849L, 5#17850L, 6#17851L, 7#17855L, cross_val#17853L]\n                  +- Project [4#17849L, 5#17850L, 6#17851L, 1#17852L, cross_val#17853L, 2#17854L, 7#17855L, 3#17856L, sum_val AS Cover_Type#17865]\n                     +- Project [sum(4)#17825L AS 4#17849L, sum(5)#17826L AS 5#17850L, sum(6)#17827L AS 6#17851L, sum(1)#17828L AS 1#17852L, sum(cross_val)#17829L AS cross_val#17853L, sum(2)#17830L AS 2#17854L, sum(7)#17831L AS 7#17855L, sum(3)#17832L AS 3#17856L]\n                        +- Aggregate [sum(4#17753L) AS sum(4)#17825L, sum(5#17754L) AS sum(5)#17826L, sum(6#17755L) AS sum(6)#17827L, sum(1#17750L) AS sum(1)#17828L, sum(cross_val#17774L) AS sum(cross_val)#17829L, sum(2#17751L) AS sum(2)#17830L, sum(7#17756L) AS sum(7)#17831L, sum(3#17752L) AS sum(3)#17832L]\n                           +- Project [Cover_Type#17749, 1#17750L, 2#17751L, 3#17752L, 4#17753L, 5#17754L, 6#17755L, 7#17756L, cross_val#17774L]\n                              +- Join LeftOuter, (Cover_Type#17749 \u003d cast(Type#17773 as double))\n                                 :- Sort [Cover_Type#17749 ASC NULLS FIRST], true\n                                 :  +- Project [coalesce(nanvl(Cover_Type#230, cast(null as double)), cast(0.0 as double)) AS Cover_Type#17749, coalesce(1#17726L, cast(0.0 as bigint)) AS 1#17750L, coalesce(2#17727L, cast(0.0 as bigint)) AS 2#17751L, coalesce(3#17728L, cast(0.0 as bigint)) AS 3#17752L, coalesce(4#17729L, cast(0.0 as bigint)) AS 4#17753L, coalesce(5#17730L, cast(0.0 as bigint)) AS 5#17754L, coalesce(6#17731L, cast(0.0 as bigint)) AS 6#17755L, coalesce(7#17732L, cast(0.0 as bigint)) AS 7#17756L]\n                                 :     +- Project [Cover_Type#230, __pivot_count(1) AS `count` AS `count(1) AS ``count```#17725[0] AS 1#17726L, __pivot_count(1) AS `count` AS `count(1) AS ``count```#17725[1] AS 2#17727L, __pivot_count(1) AS `count` AS `count(1) AS ``count```#17725[2] AS 3#17728L, __pivot_count(1) AS `count` AS `count(1) AS ``count```#17725[3] AS 4#17729L, __pivot_count(1) AS `count` AS `count(1) AS ``count```#17725[4] AS 5#17730L, __pivot_count(1) AS `count` AS `count(1) AS ``count```#17725[5] AS 6#17731L, __pivot_count(1) AS `count` AS `count(1) AS ``count```#17725[6] AS 7#17732L]\n                                 :        +- Aggregate [Cover_Type#230], [Cover_Type#230, pivotfirst(prediction#5860, count(1) AS `count`#17709L, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 0, 0) AS __pivot_count(1) AS `count` AS `count(1) AS ``count```#17725]\n                                 :           +- Aggregate [Cover_Type#230, prediction#5860], [Cover_Type#230, prediction#5860, count(1) AS count(1) AS `count`#17709L]\n                                 :              +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Cover_Type#230, wilderness#1346, soil#1506, featureVector#5793, indexedVector#5809, rawPrediction#5825, probability#5842, UDF(rawPrediction#5825) AS prediction#5860]\n                                 :                 +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Cover_Type#230, wilderness#1346, soil#1506, featureVector#5793, indexedVector#5809, rawPrediction#5825, UDF(rawPrediction#5825) AS probability#5842]\n                                 :                    +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Cover_Type#230, wilderness#1346, soil#1506, featureVector#5793, indexedVector#5809, UDF(indexedVector#5809) AS rawPrediction#5825]\n                                 :                       +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Cover_Type#230, wilderness#1346, soil#1506, featureVector#5793, UDF(featureVector#5793) AS indexedVector#5809]\n                                 :                          +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Cover_Type#230, wilderness#1346, soil#1506, UDF(named_struct(Elevation_double_vecAssembler_9b79ec3ff6d6, cast(Elevation#120 as double), Aspect_double_vecAssembler_9b79ec3ff6d6, cast(Aspect#121 as double), Slope_double_vecAssembler_9b79ec3ff6d6, cast(Slope#122 as double), Horizontal_Distance_To_Hydrology_double_vecAssembler_9b79ec3ff6d6, cast(Horizontal_Distance_To_Hydrology#123 as double), Vertical_Distance_To_Hydrology_double_vecAssembler_9b79ec3ff6d6, cast(Vertical_Distance_To_Hydrology#124 as double), Horizontal_Distance_To_Roadways_double_vecAssembler_9b79ec3ff6d6, cast(Horizontal_Distance_To_Roadways#125 as double), Hillshade_9am_double_vecAssembler_9b79ec3ff6d6, cast(Hillshade_9am#126 as double), Hillshade_Noon_double_vecAssembler_9b79ec3ff6d6, cast(Hillshade_Noon#127 as double), Hillshade_3pm_double_vecAssembler_9b79ec3ff6d6, cast(Hillshade_3pm#128 as double), Horizontal_Distance_To_Fire_Points_double_vecAssembler_9b79ec3ff6d6, cast(Horizontal_Distance_To_Fire_Points#129 as double), wilderness, wilderness#1346, soil, soil#1506)) AS featureVector#5793]\n                                 :                             +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Cover_Type#230, wilderness#1346, UDF(soil#1439) AS soil#1506]\n                                 :                                +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Cover_Type#230, wilderness#1346, soil#1439]\n                                 :                                   +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Soil_Type_0#134, Soil_Type_1#135, Soil_Type_2#136, Soil_Type_3#137, Soil_Type_4#138, Soil_Type_5#139, Soil_Type_6#140, Soil_Type_7#141, Soil_Type_8#142, Soil_Type_9#143, Soil_Type_10#144, Soil_Type_11#145, Soil_Type_12#146, Soil_Type_13#147, ... 29 more fields]\n                                 :                                      +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Soil_Type_0#134, Soil_Type_1#135, Soil_Type_2#136, Soil_Type_3#137, Soil_Type_4#138, Soil_Type_5#139, Soil_Type_6#140, Soil_Type_7#141, Soil_Type_8#142, Soil_Type_9#143, Soil_Type_10#144, Soil_Type_11#145, Soil_Type_12#146, Soil_Type_13#147, ... 28 more fields]\n                                 :                                         +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Soil_Type_0#134, Soil_Type_1#135, Soil_Type_2#136, Soil_Type_3#137, Soil_Type_4#138, Soil_Type_5#139, Soil_Type_6#140, Soil_Type_7#141, Soil_Type_8#142, Soil_Type_9#143, Soil_Type_10#144, Soil_Type_11#145, Soil_Type_12#146, Soil_Type_13#147, ... 28 more fields]\n                                 :                                            +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Wilderness_Area_0#130, Wilderness_Area_1#131, Wilderness_Area_2#132, Wilderness_Area_3#133, Soil_Type_0#134, Soil_Type_1#135, Soil_Type_2#136, Soil_Type_3#137, Soil_Type_4#138, Soil_Type_5#139, Soil_Type_6#140, Soil_Type_7#141, Soil_Type_8#142, Soil_Type_9#143, ... 32 more fields]\n                                 :                                               +- Sample 0.9, 1.0, false, 4912836352977398653\n                                 :                                                  +- Sort [Elevation#120 ASC NULLS FIRST, Aspect#121 ASC NULLS FIRST, Slope#122 ASC NULLS FIRST, Horizontal_Distance_To_Hydrology#123 ASC NULLS FIRST, Vertical_Distance_To_Hydrology#124 ASC NULLS FIRST, Horizontal_Distance_To_Roadways#125 ASC NULLS FIRST, Hillshade_9am#126 ASC NULLS FIRST, Hillshade_Noon#127 ASC NULLS FIRST, Hillshade_3pm#128 ASC NULLS FIRST, Horizontal_Distance_To_Fire_Points#129 ASC NULLS FIRST, Wilderness_Area_0#130 ASC NULLS FIRST, Wilderness_Area_1#131 ASC NULLS FIRST, Wilderness_Area_2#132 ASC NULLS FIRST, Wilderness_Area_3#133 ASC NULLS FIRST, Soil_Type_0#134 ASC NULLS FIRST, Soil_Type_1#135 ASC NULLS FIRST, Soil_Type_2#136 ASC NULLS FIRST, Soil_Type_3#137 ASC NULLS FIRST, Soil_Type_4#138 ASC NULLS FIRST, Soil_Type_5#139 ASC NULLS FIRST, Soil_Type_6#140 ASC NULLS FIRST, Soil_Type_7#141 ASC NULLS FIRST, Soil_Type_8#142 ASC NULLS FIRST, Soil_Type_9#143 ASC NULLS FIRST, ... 31 more fields], false\n                                 :                                                     +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Wilderness_Area_0#130, Wilderness_Area_1#131, Wilderness_Area_2#132, Wilderness_Area_3#133, Soil_Type_0#134, Soil_Type_1#135, Soil_Type_2#136, Soil_Type_3#137, Soil_Type_4#138, Soil_Type_5#139, Soil_Type_6#140, Soil_Type_7#141, Soil_Type_8#142, Soil_Type_9#143, ... 31 more fields]\n                                 :                                                        +- Project [_c0#10 AS Elevation#120, _c1#11 AS Aspect#121, _c2#12 AS Slope#122, _c3#13 AS Horizontal_Distance_To_Hydrology#123, _c4#14 AS Vertical_Distance_To_Hydrology#124, _c5#15 AS Horizontal_Distance_To_Roadways#125, _c6#16 AS Hillshade_9am#126, _c7#17 AS Hillshade_Noon#127, _c8#18 AS Hillshade_3pm#128, _c9#19 AS Horizontal_Distance_To_Fire_Points#129, _c10#20 AS Wilderness_Area_0#130, _c11#21 AS Wilderness_Area_1#131, _c12#22 AS Wilderness_Area_2#132, _c13#23 AS Wilderness_Area_3#133, _c14#24 AS Soil_Type_0#134, _c15#25 AS Soil_Type_1#135, _c16#26 AS Soil_Type_2#136, _c17#27 AS Soil_Type_3#137, _c18#28 AS Soil_Type_4#138, _c19#29 AS Soil_Type_5#139, _c20#30 AS Soil_Type_6#140, _c21#31 AS Soil_Type_7#141, _c22#32 AS Soil_Type_8#142, _c23#33 AS Soil_Type_9#143, ... 31 more fields]\n                                 :                                                           +- Relation[_c0#10,_c1#11,_c2#12,_c3#13,_c4#14,_c5#15,_c6#16,_c7#17,_c8#18,_c9#19,_c10#20,_c11#21,_c12#22,_c13#23,_c14#24,_c15#25,_c16#26,_c17#27,_c18#28,_c19#29,_c20#30,_c21#31,_c22#32,_c23#33,... 31 more fields] csv\n                                 +- Project [_1#17770 AS Type#17773, _2#17771L AS cross_val#17774L]\n                                    +- SerializeFromObject [assertnotnull(assertnotnull(input[0, scala.Tuple2, true]))._1 AS _1#17770, assertnotnull(assertnotnull(input[0, scala.Tuple2, true]))._2 AS _2#17771L]\n                                       +- MapElements \u003cfunction1\u003e, interface org.apache.spark.sql.Row, [StructField(Cover_Type,DoubleType,false), StructField(1,LongType,true), StructField(2,LongType,true), StructField(3,LongType,true), StructField(4,LongType,true), StructField(5,LongType,true), StructField(6,LongType,true), StructField(7,LongType,true)], obj#17769: scala.Tuple2\n                                          +- DeserializeToObject createexternalrow(Cover_Type#17749, 1#17750L, 2#17751L, 3#17752L, 4#17753L, 5#17754L, 6#17755L, 7#17756L, StructField(Cover_Type,DoubleType,false), StructField(1,LongType,true), StructField(2,LongType,true), StructField(3,LongType,true), StructField(4,LongType,true), StructField(5,LongType,true), StructField(6,LongType,true), StructField(7,LongType,true)), obj#17768: org.apache.spark.sql.Row\n                                             +- Sort [Cover_Type#17749 ASC NULLS FIRST], true\n                                                +- Project [coalesce(nanvl(Cover_Type#230, cast(null as double)), cast(0.0 as double)) AS Cover_Type#17749, coalesce(1#17726L, cast(0.0 as bigint)) AS 1#17750L, coalesce(2#17727L, cast(0.0 as bigint)) AS 2#17751L, coalesce(3#17728L, cast(0.0 as bigint)) AS 3#17752L, coalesce(4#17729L, cast(0.0 as bigint)) AS 4#17753L, coalesce(5#17730L, cast(0.0 as bigint)) AS 5#17754L, coalesce(6#17731L, cast(0.0 as bigint)) AS 6#17755L, coalesce(7#17732L, cast(0.0 as bigint)) AS 7#17756L]\n                                                   +- Project [Cover_Type#230, __pivot_count(1) AS `count` AS `count(1) AS ``count```#17725[0] AS 1#17726L, __pivot_count(1) AS `count` AS `count(1) AS ``count```#17725[1] AS 2#17727L, __pivot_count(1) AS `count` AS `count(1) AS ``count```#17725[2] AS 3#17728L, __pivot_count(1) AS `count` AS `count(1) AS ``count```#17725[3] AS 4#17729L, __pivot_count(1) AS `count` AS `count(1) AS ``count```#17725[4] AS 5#17730L, __pivot_count(1) AS `count` AS `count(1) AS ``count```#17725[5] AS 6#17731L, __pivot_count(1) AS `count` AS `count(1) AS ``count```#17725[6] AS 7#17732L]\n                                                      +- Aggregate [Cover_Type#230], [Cover_Type#230, pivotfirst(prediction#5860, count(1) AS `count`#17709L, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 0, 0) AS __pivot_count(1) AS `count` AS `count(1) AS ``count```#17725]\n                                                         +- Aggregate [Cover_Type#230, prediction#5860], [Cover_Type#230, prediction#5860, count(1) AS count(1) AS `count`#17709L]\n                                                            +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Cover_Type#230, wilderness#1346, soil#1506, featureVector#5793, indexedVector#5809, rawPrediction#5825, probability#5842, UDF(rawPrediction#5825) AS prediction#5860]\n                                                               +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Cover_Type#230, wilderness#1346, soil#1506, featureVector#5793, indexedVector#5809, rawPrediction#5825, UDF(rawPrediction#5825) AS probability#5842]\n                                                                  +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Cover_Type#230, wilderness#1346, soil#1506, featureVector#5793, indexedVector#5809, UDF(indexedVector#5809) AS rawPrediction#5825]\n                                                                     +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Cover_Type#230, wilderness#1346, soil#1506, featureVector#5793, UDF(featureVector#5793) AS indexedVector#5809]\n                                                                        +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Cover_Type#230, wilderness#1346, soil#1506, UDF(named_struct(Elevation_double_vecAssembler_9b79ec3ff6d6, cast(Elevation#120 as double), Aspect_double_vecAssembler_9b79ec3ff6d6, cast(Aspect#121 as double), Slope_double_vecAssembler_9b79ec3ff6d6, cast(Slope#122 as double), Horizontal_Distance_To_Hydrology_double_vecAssembler_9b79ec3ff6d6, cast(Horizontal_Distance_To_Hydrology#123 as double), Vertical_Distance_To_Hydrology_double_vecAssembler_9b79ec3ff6d6, cast(Vertical_Distance_To_Hydrology#124 as double), Horizontal_Distance_To_Roadways_double_vecAssembler_9b79ec3ff6d6, cast(Horizontal_Distance_To_Roadways#125 as double), Hillshade_9am_double_vecAssembler_9b79ec3ff6d6, cast(Hillshade_9am#126 as double), Hillshade_Noon_double_vecAssembler_9b79ec3ff6d6, cast(Hillshade_Noon#127 as double), Hillshade_3pm_double_vecAssembler_9b79ec3ff6d6, cast(Hillshade_3pm#128 as double), Horizontal_Distance_To_Fire_Points_double_vecAssembler_9b79ec3ff6d6, cast(Horizontal_Distance_To_Fire_Points#129 as double), wilderness, wilderness#1346, soil, soil#1506)) AS featureVector#5793]\n                                                                           +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Cover_Type#230, wilderness#1346, UDF(soil#1439) AS soil#1506]\n                                                                              +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Cover_Type#230, wilderness#1346, soil#1439]\n                                                                                 +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Soil_Type_0#134, Soil_Type_1#135, Soil_Type_2#136, Soil_Type_3#137, Soil_Type_4#138, Soil_Type_5#139, Soil_Type_6#140, Soil_Type_7#141, Soil_Type_8#142, Soil_Type_9#143, Soil_Type_10#144, Soil_Type_11#145, Soil_Type_12#146, Soil_Type_13#147, ... 29 more fields]\n                                                                                    +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Soil_Type_0#134, Soil_Type_1#135, Soil_Type_2#136, Soil_Type_3#137, Soil_Type_4#138, Soil_Type_5#139, Soil_Type_6#140, Soil_Type_7#141, Soil_Type_8#142, Soil_Type_9#143, Soil_Type_10#144, Soil_Type_11#145, Soil_Type_12#146, Soil_Type_13#147, ... 28 more fields]\n                                                                                       +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Soil_Type_0#134, Soil_Type_1#135, Soil_Type_2#136, Soil_Type_3#137, Soil_Type_4#138, Soil_Type_5#139, Soil_Type_6#140, Soil_Type_7#141, Soil_Type_8#142, Soil_Type_9#143, Soil_Type_10#144, Soil_Type_11#145, Soil_Type_12#146, Soil_Type_13#147, ... 28 more fields]\n                                                                                          +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Wilderness_Area_0#130, Wilderness_Area_1#131, Wilderness_Area_2#132, Wilderness_Area_3#133, Soil_Type_0#134, Soil_Type_1#135, Soil_Type_2#136, Soil_Type_3#137, Soil_Type_4#138, Soil_Type_5#139, Soil_Type_6#140, Soil_Type_7#141, Soil_Type_8#142, Soil_Type_9#143, ... 32 more fields]\n                                                                                             +- Sample 0.9, 1.0, false, 4912836352977398653\n                                                                                                +- Sort [Elevation#120 ASC NULLS FIRST, Aspect#121 ASC NULLS FIRST, Slope#122 ASC NULLS FIRST, Horizontal_Distance_To_Hydrology#123 ASC NULLS FIRST, Vertical_Distance_To_Hydrology#124 ASC NULLS FIRST, Horizontal_Distance_To_Roadways#125 ASC NULLS FIRST, Hillshade_9am#126 ASC NULLS FIRST, Hillshade_Noon#127 ASC NULLS FIRST, Hillshade_3pm#128 ASC NULLS FIRST, Horizontal_Distance_To_Fire_Points#129 ASC NULLS FIRST, Wilderness_Area_0#130 ASC NULLS FIRST, Wilderness_Area_1#131 ASC NULLS FIRST, Wilderness_Area_2#132 ASC NULLS FIRST, Wilderness_Area_3#133 ASC NULLS FIRST, Soil_Type_0#134 ASC NULLS FIRST, Soil_Type_1#135 ASC NULLS FIRST, Soil_Type_2#136 ASC NULLS FIRST, Soil_Type_3#137 ASC NULLS FIRST, Soil_Type_4#138 ASC NULLS FIRST, Soil_Type_5#139 ASC NULLS FIRST, Soil_Type_6#140 ASC NULLS FIRST, Soil_Type_7#141 ASC NULLS FIRST, Soil_Type_8#142 ASC NULLS FIRST, Soil_Type_9#143 ASC NULLS FIRST, ... 31 more fields], false\n                                                                                                   +- Project [Elevation#120, Aspect#121, Slope#122, Horizontal_Distance_To_Hydrology#123, Vertical_Distance_To_Hydrology#124, Horizontal_Distance_To_Roadways#125, Hillshade_9am#126, Hillshade_Noon#127, Hillshade_3pm#128, Horizontal_Distance_To_Fire_Points#129, Wilderness_Area_0#130, Wilderness_Area_1#131, Wilderness_Area_2#132, Wilderness_Area_3#133, Soil_Type_0#134, Soil_Type_1#135, Soil_Type_2#136, Soil_Type_3#137, Soil_Type_4#138, Soil_Type_5#139, Soil_Type_6#140, Soil_Type_7#141, Soil_Type_8#142, Soil_Type_9#143, ... 31 more fields]\n                                                                                                      +- Project [_c0#10 AS Elevation#120, _c1#11 AS Aspect#121, _c2#12 AS Slope#122, _c3#13 AS Horizontal_Distance_To_Hydrology#123, _c4#14 AS Vertical_Distance_To_Hydrology#124, _c5#15 AS Horizontal_Distance_To_Roadways#125, _c6#16 AS Hillshade_9am#126, _c7#17 AS Hillshade_Noon#127, _c8#18 AS Hillshade_3pm#128, _c9#19 AS Horizontal_Distance_To_Fire_Points#129, _c10#20 AS Wilderness_Area_0#130, _c11#21 AS Wilderness_Area_1#131, _c12#22 AS Wilderness_Area_2#132, _c13#23 AS Wilderness_Area_3#133, _c14#24 AS Soil_Type_0#134, _c15#25 AS Soil_Type_1#135, _c16#26 AS Soil_Type_2#136, _c17#27 AS Soil_Type_3#137, _c18#28 AS Soil_Type_4#138, _c19#29 AS Soil_Type_5#139, _c20#30 AS Soil_Type_6#140, _c21#31 AS Soil_Type_7#141, _c22#32 AS Soil_Type_8#142, _c23#33 AS Soil_Type_9#143, ... 31 more fields]\n                                                                                                         +- Relation[_c0#10,_c1#11,_c2#12,_c3#13,_c4#14,_c5#15,_c6#16,_c7#17,_c8#18,_c9#19,_c10#20,_c11#21,_c12#22,_c13#23,_c14#24,_c15#25,_c16#26,_c17#27,_c18#28,_c19#29,_c20#30,_c21#31,_c22#32,_c23#33,... 31 more fields] csv\n\n  at org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2.applyOrElse(CheckAnalysis.scala:88)\n  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2.applyOrElse(CheckAnalysis.scala:85)\n  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:289)\n  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:289)\n  at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n  at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:288)\n  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:286)\n  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:286)\n  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:306)\n  at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n  at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:304)\n  at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:286)\n  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:286)\n  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:286)\n  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:306)\n  at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n  at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:304)\n  at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:286)\n  at org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:95)\n  at org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:95)\n  at org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:107)\n  at org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:107)\n  at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n  at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:106)\n  at org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:118)\n  at org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1$1.apply(QueryPlan.scala:122)\n  at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n  at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n  at scala.collection.immutable.List.foreach(List.scala:381)\n  at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n  at scala.collection.immutable.List.map(List.scala:285)\n  at org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:122)\n  at org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$2.apply(QueryPlan.scala:127)\n  at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n  at org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:127)\n  at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:95)\n  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:85)\n  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:80)\n  at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:127)\n  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:80)\n  at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:92)\n  at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:105)\n  at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:57)\n  at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:55)\n  at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:47)\n  at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:74)\n  at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withPlan(Dataset.scala:3296)\n  at org.apache.spark.sql.Dataset.select(Dataset.scala:1307)\n  at org.apache.spark.sql.Dataset.withColumns(Dataset.scala:2192)\n  at org.apache.spark.sql.Dataset.withColumn(Dataset.scala:2159)\n  ... 54 elided\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1546332735951_2112292878",
      "id": "20190101-165215_157768855",
      "dateCreated": "2019-01-01 16:52:15.951",
      "dateStarted": "2019-01-01 17:28:01.625",
      "dateFinished": "2019-01-01 17:29:36.183",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n- 增加每个特征的预测结果统计\n   - cross_val: 正确预测值\n   - sum: 预测结果总计\n   - rat: 预测的正确率： cross_val / sum\n",
      "user": "hadoop",
      "dateUpdated": "2019-01-01 17:31:24.470",
      "config": {
        "colWidth": 6.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cul\u003e\n  \u003cli\u003e增加每个特征的预测结果统计\u003c/li\u003e\n  \u003cli\u003ecross_val: 正确预测值\u003c/li\u003e\n  \u003cli\u003esum: 预测结果总计\u003c/li\u003e\n  \u003cli\u003erat: 预测的正确率： cross_val / sum\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1546332770207_602925093",
      "id": "20190101-165250_1347405289",
      "dateCreated": "2019-01-01 16:52:50.207",
      "dateStarted": "2019-01-01 17:31:24.470",
      "dateFinished": "2019-01-01 17:31:24.479",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "统计表格",
      "text": "%sql\nselect\n*\nfrom staticPercentTable\n",
      "user": "hadoop",
      "dateUpdated": "2019-01-01 17:44:37.616",
      "config": {
        "colWidth": 6.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "1": "string",
                      "2": "string",
                      "3": "string",
                      "4": "string",
                      "5": "string",
                      "6": "string",
                      "7": "string",
                      "Cover_Type": "string",
                      "cross_val": "string",
                      "sum": "string",
                      "rat": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          }
        },
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/sql",
        "editorHide": false,
        "tableHide": false,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TABLE",
            "data": "Cover_Type\t1\t2\t3\t4\t5\t6\t7\tcross_val\tsum\trat\n1.0\t19753\t1321\t1\t0\t9\t1\t35\t19753\t21120\t0.9352746212121212\n2.0\t816\t27147\t49\t0\t46\t35\t4\t27147\t28097\t0.9661885610563405\n3.0\t0\t62\t3430\t14\t2\t78\t0\t3430\t3586\t0.9564974902398216\n4.0\t0\t0\t44\t234\t0\t11\t0\t234\t289\t0.8096885813148789\n5.0\t11\t153\t6\t0\t746\t3\t0\t746\t919\t0.8117519042437432\n6.0\t1\t46\t99\t8\t3\t1567\t0\t1567\t1724\t0.9089327146171694\n7.0\t83\t10\t0\t0\t0\t0\t2036\t2036\t2129\t0.9563175199624236\nsum\t20664\t28739\t3629\t256\t806\t1695\t2075\t54913\t57864\t0.949001106041753\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1546335817878_-1316264769",
      "id": "20190101-174337_1620177813",
      "dateCreated": "2019-01-01 17:43:37.878",
      "dateStarted": "2019-01-01 17:44:10.134",
      "dateFinished": "2019-01-01 17:44:17.442",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "测试集：分类样本数(sum) VS 预测正确样本数(cross_val)",
      "text": "%sql\nselect\n`Cover_Type`, `cross_val`, `sum`\nfrom staticPercentTable\nwhere Cover_Type !\u003d \u0027sum\u0027\n",
      "user": "hadoop",
      "dateUpdated": "2019-01-05 10:02:40.232",
      "config": {
        "colWidth": 4.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {
          "0": {
            "graph": {
              "mode": "multiBarChart",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {
                    "columns": [
                      {
                        "name": "Cover_Type",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      },
                      {
                        "name": "1",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      },
                      {
                        "name": "2",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      },
                      {
                        "name": "3",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      },
                      {
                        "name": "4",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      },
                      {
                        "name": "5",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      },
                      {
                        "name": "6",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      },
                      {
                        "name": "7",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      },
                      {
                        "name": "cross_val",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      }
                    ],
                    "scrollFocus": {},
                    "selection": [],
                    "grouping": {
                      "grouping": [],
                      "aggregations": [],
                      "rowExpandedStates": {}
                    },
                    "treeView": {},
                    "pagination": {
                      "paginationCurrentPage": 1.0,
                      "paginationPageSize": 250.0
                    }
                  },
                  "tableColumnTypeState": {
                    "names": {
                      "Cover_Type": "string",
                      "cross_val": "string",
                      "sum": "string",
                      "percent": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                },
                "multiBarChart": {
                  "rotate": {
                    "degree": "-45"
                  },
                  "xLabelStatus": "default",
                  "stacked": false
                },
                "stackedAreaChart": {
                  "rotate": {
                    "degree": "-45"
                  },
                  "xLabelStatus": "default"
                }
              },
              "commonSetting": {},
              "keys": [
                {
                  "name": "Cover_Type",
                  "index": 0.0,
                  "aggr": "sum"
                }
              ],
              "groups": [],
              "values": [
                {
                  "name": "cross_val",
                  "index": 1.0,
                  "aggr": "sum"
                },
                {
                  "name": "sum",
                  "index": 2.0,
                  "aggr": "sum"
                }
              ]
            },
            "helium": {}
          }
        },
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/sql",
        "title": true,
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TABLE",
            "data": "Cover_Type\tcross_val\tsum\n1.0\t19753\t21120\n2.0\t27147\t28097\n3.0\t3430\t3586\n4.0\t234\t289\n5.0\t746\t919\n6.0\t1567\t1724\n7.0\t2036\t2129\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1546334590835_1226784990",
      "id": "20190101-172310_1692614761",
      "dateCreated": "2019-01-01 17:23:10.835",
      "dateStarted": "2019-01-01 17:44:56.276",
      "dateFinished": "2019-01-01 17:45:04.302",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "样本的预测准确率",
      "text": "%sql\nselect\n`Cover_Type`, ROUND(`rat` * 100, 2) as `percent`\nfrom staticPercentTable\nwhere Cover_Type !\u003d \u0027sum\u0027\n\n",
      "user": "hadoop",
      "dateUpdated": "2019-01-05 10:02:40.498",
      "config": {
        "colWidth": 4.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {
          "0": {
            "graph": {
              "mode": "stackedAreaChart",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "Cover_Type": "string",
                      "percent": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                },
                "lineChart": {
                  "rotate": {
                    "degree": "-45"
                  },
                  "xLabelStatus": "default"
                },
                "stackedAreaChart": {
                  "rotate": {
                    "degree": "-45"
                  },
                  "xLabelStatus": "default"
                },
                "pieChart": {},
                "multiBarChart": {
                  "rotate": {
                    "degree": "-45"
                  },
                  "xLabelStatus": "default"
                }
              },
              "commonSetting": {},
              "keys": [
                {
                  "name": "Cover_Type",
                  "index": 0.0,
                  "aggr": "sum"
                }
              ],
              "groups": [],
              "values": [
                {
                  "name": "percent",
                  "index": 1.0,
                  "aggr": "sum"
                }
              ]
            },
            "helium": {}
          }
        },
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/sql",
        "editorHide": true,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TABLE",
            "data": "Cover_Type\tpercent\n1.0\t93.53\n2.0\t96.62\n3.0\t95.65\n4.0\t80.97\n5.0\t81.18\n6.0\t90.89\n7.0\t95.63\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1546333622297_-1093853294",
      "id": "20190101-170702_497267167",
      "dateCreated": "2019-01-01 17:07:02.297",
      "dateStarted": "2019-01-01 17:48:07.505",
      "dateFinished": "2019-01-01 17:48:15.283",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "测试样本的预测准确数(cross_val)VS样本总量(sum)",
      "text": "%sql\nselect\n`Cover_Type`, `cross_val`, `sum`\nfrom staticPercentTable\nwhere Cover_Type \u003d \u0027sum\u0027\n",
      "user": "hadoop",
      "dateUpdated": "2019-01-01 17:58:33.330",
      "config": {
        "colWidth": 4.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {
          "0": {
            "graph": {
              "mode": "pieChart",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "Cover_Type": "string",
                      "cross_val": "string",
                      "sum": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                },
                "pieChart": {},
                "multiBarChart": {
                  "rotate": {
                    "degree": "-45"
                  },
                  "xLabelStatus": "default"
                }
              },
              "commonSetting": {},
              "keys": [],
              "groups": [],
              "values": [
                {
                  "name": "cross_val",
                  "index": 1.0,
                  "aggr": "sum"
                },
                {
                  "name": "sum",
                  "index": 2.0,
                  "aggr": "sum"
                }
              ]
            },
            "helium": {}
          }
        },
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/sql",
        "editorHide": true,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TABLE",
            "data": "Cover_Type\tcross_val\tsum\nsum\t54913\t57864\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1546334072369_713446003",
      "id": "20190101-171432_827064185",
      "dateCreated": "2019-01-01 17:14:32.370",
      "dateStarted": "2019-01-01 17:52:31.850",
      "dateFinished": "2019-01-01 17:52:40.003",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "",
      "user": "hadoop",
      "dateUpdated": "2019-01-01 17:51:07.464",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1546334040286_-1372456975",
      "id": "20190101-171400_1073931274",
      "dateCreated": "2019-01-01 17:14:00.286",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "~Trash/spark/ml_tree",
  "id": "2E2AGZ1WD",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {
    "md:shared_process": [],
    "spark:shared_process": []
  },
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}