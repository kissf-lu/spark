{
  "paragraphs": [
    {
      "text": "val userDir \u003d \"/user/hadoop\"\n\nval linesLog \u003d spark.sparkContext.textFile(s\"$userDir/TestRoot.log\")\n ",
      "user": "hadoop",
      "dateUpdated": "2018-12-27 14:18:47.421",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "userDir: String \u003d /user/hadoop\nlinesLog: org.apache.spark.rdd.RDD[String] \u003d /user/hadoop/TestRoot.log MapPartitionsRDD[1] at textFile at \u003cconsole\u003e:25\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1545891115149_1750212539",
      "id": "20181227-141155_1226507706",
      "dateCreated": "2018-12-27 14:11:55.149",
      "dateStarted": "2018-12-27 14:18:47.431",
      "dateFinished": "2018-12-27 14:19:05.326",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val words \u003d linesLog.flatMap(l \u003d\u003e l.split(\"\u003e\"))\n\nwords.filter(_.contains(\"INFO\")).first",
      "user": "hadoop",
      "dateUpdated": "2018-12-27 14:20:59.997",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "words: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[2] at flatMap at \u003cconsole\u003e:27\nres5: String \u003d \u003cINFO\n"
          }
        ]
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://master:4042/jobs/job?id\u003d0"
          ],
          "interpreterSettingId": "spark"
        }
      },
      "apps": [],
      "jobName": "paragraph_1545891188384_1781569187",
      "id": "20181227-141308_1179177093",
      "dateCreated": "2018-12-27 14:13:08.384",
      "dateStarted": "2018-12-27 14:21:00.009",
      "dateFinished": "2018-12-27 14:21:05.262",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\n### RDD 联合操作\n\n---\n\n- 直接将RDD联合\n",
      "user": "hadoop",
      "dateUpdated": "2018-12-27 14:58:44.497",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eRDD 联合操作\u003c/h3\u003e\n\u003chr/\u003e\n\u003cul\u003e\n  \u003cli\u003e直接将RDD联合\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1545893876394_-1501725914",
      "id": "20181227-145756_97621388",
      "dateCreated": "2018-12-27 14:57:56.394",
      "dateStarted": "2018-12-27 14:58:44.497",
      "dateFinished": "2018-12-27 14:58:44.505",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val ls1Rdd \u003d (\u0027a\u0027 to \u0027h\u0027).toList\n\nval ls2Rdd \u003d (\u0027g\u0027 to \u0027k\u0027).toList\n    \nval charLs1 \u003d spark.sparkContext.parallelize(ls1Rdd)\nval charLs2 \u003d spark.sparkContext.parallelize(ls2Rdd)\n\n",
      "user": "hadoop",
      "dateUpdated": "2018-12-27 14:22:50.048",
      "config": {
        "colWidth": 6.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "ls1Rdd: List[Char] \u003d List(a, b, c, d, e, f, g, h)\nls2Rdd: List[Char] \u003d List(g, h, i, j, k)\ncharLs1: org.apache.spark.rdd.RDD[Char] \u003d ParallelCollectionRDD[4] at parallelize at \u003cconsole\u003e:25\ncharLs2: org.apache.spark.rdd.RDD[Char] \u003d ParallelCollectionRDD[5] at parallelize at \u003cconsole\u003e:25\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1545891358552_-281359933",
      "id": "20181227-141558_1666426389",
      "dateCreated": "2018-12-27 14:15:58.553",
      "dateStarted": "2018-12-27 14:21:31.715",
      "dateFinished": "2018-12-27 14:21:33.389",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "",
      "text": "charLs1.union(charLs2).collect\n\n\n\n\n\n\n\n\n\n\n",
      "user": "hadoop",
      "dateUpdated": "2018-12-27 15:00:51.103",
      "config": {
        "colWidth": 6.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "title": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "res24: Array[Char] \u003d Array(a, b, c, d, e, f, g, h, g, h, i, j, k)\n"
          }
        ]
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://master:4042/jobs/job?id\u003d6"
          ],
          "interpreterSettingId": "spark"
        }
      },
      "apps": [],
      "jobName": "paragraph_1545891691702_1773217175",
      "id": "20181227-142131_1179167804",
      "dateCreated": "2018-12-27 14:21:31.702",
      "dateStarted": "2018-12-27 14:59:05.908",
      "dateFinished": "2018-12-27 14:59:06.313",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### RDD fold 操作\n\n---\n\n- parallelize(seq: Seq[T], numSlices: Int \u003d defaultParallelism)\n   - defaultParallelism: 默认取Spark cup的核心并发数(本列为4)\n   - fold(init) (opt) \n      - 1 fold将初始值init 和 opt函数作用到每个RDD分区的数据 各个分区分别结算fold\n      - 2 最后对各个分区的数据汇总，以init 和 opt 汇总\n      \n---\n\n- eg intListVal.fold(1) (_ + _ )： 数据长度为3， 默认分区数为8， 只能分3个区并行计算\n   - 分区计算： 1 + 1； 1 + 2； 1 + 3\n   - 汇总计算： 2 + 3 + 4 + 1 \u003d 10\n",
      "user": "hadoop",
      "dateUpdated": "2018-12-27 15:22:31.607",
      "config": {
        "colWidth": 6.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eRDD fold 操作\u003c/h3\u003e\n\u003chr/\u003e\n\u003cul\u003e\n  \u003cli\u003eparallelize(seq: Seq[T], numSlices: Int \u003d defaultParallelism)\u003c/li\u003e\n  \u003cli\u003edefaultParallelism: 默认取Spark cup的核心并发数(本列为4)\u003c/li\u003e\n  \u003cli\u003efold(init) (opt)\n    \u003cul\u003e\n      \u003cli\u003e1 fold将初始值init 和 opt函数作用到每个RDD分区的数据 各个分区分别结算fold\u003c/li\u003e\n      \u003cli\u003e2 最后对各个分区的数据汇总，以init 和 opt 汇总\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\u003chr/\u003e\n\u003cul\u003e\n  \u003cli\u003eeg intListVal.fold(1) (_ + _ )： 数据长度为3， 默认分区数为8， 只能分3个区并行计算\u003c/li\u003e\n  \u003cli\u003e分区计算： 1 + 1； 1 + 2； 1 + 3\u003c/li\u003e\n  \u003cli\u003e汇总计算： 2 + 3 + 4 + 1 \u003d 10\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1545892051644_-1022425698",
      "id": "20181227-142731_2044586761",
      "dateCreated": "2018-12-27 14:27:31.645",
      "dateStarted": "2018-12-27 15:22:31.607",
      "dateFinished": "2018-12-27 15:22:31.620",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val intListVal \u003d spark.sparkContext.parallelize((1 to 3).toList)\n\nintListVal.fold(1)(_ + _)\n\n",
      "user": "hadoop",
      "dateUpdated": "2018-12-27 15:24:09.173",
      "config": {
        "colWidth": 6.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {
                    "columns": [
                      {
                        "name": "max(timestamp)",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      },
                      {
                        "name": "min(timestamp)",
                        "visible": true,
                        "width": "*",
                        "sort": {},
                        "filters": [
                          {}
                        ],
                        "pinned": ""
                      }
                    ],
                    "scrollFocus": {},
                    "selection": [],
                    "grouping": {
                      "grouping": [],
                      "aggregations": [],
                      "rowExpandedStates": {}
                    },
                    "treeView": {},
                    "pagination": {
                      "paginationCurrentPage": 1.0,
                      "paginationPageSize": 250.0
                    }
                  },
                  "tableColumnTypeState": {
                    "updated": false,
                    "names": {
                      "max(timestamp)": "string",
                      "min(timestamp)": "string"
                    }
                  },
                  "updated": false,
                  "initialized": false,
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  }
                },
                "multiBarChart": {
                  "rotate": {
                    "degree": "-45"
                  },
                  "xLabelStatus": "default"
                },
                "stackedAreaChart": {
                  "rotate": {
                    "degree": "-45"
                  },
                  "xLabelStatus": "default"
                },
                "lineChart": {
                  "rotate": {
                    "degree": "-45"
                  },
                  "xLabelStatus": "default"
                },
                "pieChart": {}
              },
              "commonSetting": {},
              "keys": [],
              "groups": [
                {
                  "name": "max(timestamp)",
                  "index": 0.0,
                  "aggr": "sum"
                },
                {
                  "name": "min(timestamp)",
                  "index": 1.0,
                  "aggr": "sum"
                }
              ],
              "values": []
            },
            "helium": {}
          }
        },
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "intListVal: org.apache.spark.rdd.RDD[Int] \u003d ParallelCollectionRDD[2] at parallelize at \u003cconsole\u003e:23\nres8: Int \u003d 15\n"
          }
        ]
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://master:4042/jobs/job?id\u003d2"
          ],
          "interpreterSettingId": "spark"
        }
      },
      "apps": [],
      "jobName": "paragraph_1545892507425_1229127297",
      "id": "20181227-143507_886631687",
      "dateCreated": "2018-12-27 14:35:07.426",
      "dateStarted": "2018-12-27 15:24:09.189",
      "dateFinished": "2018-12-27 15:24:09.969",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "user": "hadoop",
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1545893308062_-1950724019",
      "id": "20181227-144828_374008171",
      "dateCreated": "2018-12-27 14:48:28.062",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "BDAWS/BDAWS-3-RDD",
  "id": "2E24X6SHC",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {
    "md:shared_process": [],
    "spark:shared_process": []
  },
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}